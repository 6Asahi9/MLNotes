![](/images/image_2025-03-03_111654501.png)

### Why Use Momentum?
Instead of just using the gradient to update 
θ, we accumulate past gradients (like a rolling average). This helps us move faster in the correct direction and avoid oscillations.

### The Problem with Vanilla Gradient Descent
Imagine Miya running down a bumpy hill.

* If she just follows the steepest slope at each step, she might zigzag left and right and take forever to reach the bottom.
* That’s because the gradient in some directions is large (causing sharp moves), while in others it’s small (slowing down progress).

### What Was Hinton Thinking?
He thought:
👉 “What if instead of just following the gradient, we add some memory?”

His Thought Process Step by Step:
1. Instead of moving only based on the current gradient (∇J(θ)), keep track of the past gradients.
2. Store a "velocity" term that remembers past updates.
3. Smooth things out by giving more weight to recent gradients but not forgetting old ones completely.
4. Use this velocity term to update θ, so it moves in a more stable and faster way.

![](/images/image_2025-03-03_111938120.png)

![](/images/image_2025-03-03_112035130.png)

### First, What Is That Ugly Triangle ( ∇ )?
That upside-down triangle is called nabla — fancy name for the gradient.

Simply put, the gradient is just the direction and speed of the fastest increase in the function.

If Miya is walking on a hill, the gradient tells her:

👉 “Hey Miya, if you want to climb the hill faster, head this way!”

But since we want to minimize the hill (go downhill), we move in the opposite direction of the gradient.

### Why the Hell Is There (1 - β)?
Now this is where Hinton the Old Hag gets sneaky.

He didn't want to treat the past and the present equally.

If Miya's been rolling down for a while, she should keep that momentum going (big β).

But if she's just starting out, she needs to pay more attention to the slope (small β).

he formula is basically saying:

vt =90% Old Momentum+10% Current Gradient

👉 The 1−β is the 10% part.

Without it, the past would completely overshadow the present

When scientists use the word Momentum, they mean something like:

👉 “Forget the current force a little bit and rely more on the past forces.”

But we can't only rely on the past, right? Miya still needs to know where the hill is steep right now.

That's why they added this (1 - β).

(βv t−1 ->	Past velocity ->	Keep the memory of past movements (like Miya remembers how to run fast on a smooth road).)

((1−β) ->	How much we trust the current gradient ->	Higher β = more memory, less trust in the current gradient.)

### What Would Happen If There Was No (1 - β)?
Miya would just keep running based on her past memory forever without caring where the hill is steep right now.

With (1 - β), Hinton made sure Miya always listens a little bit to the current hill steepness — like sniffing the ground before sprinting.

![](/images/image_2025-03-03_114003056.png)

### Wait... Why Did He Choose (1 - β) and Not Just β?
Because if he used β alone, Miya would never try new paths.

This (1 - β) ensures Miya sniffs around a little bit every time before running.

### Imagine Miya on a hill:

She remembers how she ran yesterday (β v_{t-1}).

She sniffs the hill every few steps ((1 - β) ∇J(θ)).

Then she updates her running speed (v_t).

And finally, she moves forward smoothly.

### What Is Velocity Anyway? 🚨
Velocity is nothing but... 👉 The rolling speed of Miya's fluffy little body.

Hinton was trying to imitate physics.

In physics:

Position = where Miya is now.

Velocity = how fast and in which direction she's moving.

Instead of updating the position directly, he thought:

👉 “Let’s update Miya's speed (velocity) first, then use that speed to update her position.”

Why Call It Velocity?

Because it's not just the gradient anymore — it's how the gradients accumulate over time.

![](/images/image_2025-03-03_112318233.png)

### Final Metaphor 🔥🔥
Imagine Miya kneading your lap:

* Her paws pressing = Gradient
* How stubborn she is about kneading = β
* How hard she presses with each paw movement = (1 - β)
* If she keeps kneading at the same spot, her paws will sink deeper and deeper (accumulating momentum).
* But if she randomly presses harder sometimes, that's the current gradient kicking in.
