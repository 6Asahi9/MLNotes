### 1️⃣ Linear Regression 
it doesn’t ignore far-away points—it treats all points equally when finding the best-fit line. It minimizes the error across all points, even if some are far away.

### 2️⃣ Locally Weighted Regression (LWR) 
it is different because it prioritizes nearby points and almost ignores far-away ones. So, instead of one fixed line, it creates different lines based on local neighborhoods of points.

### 3️⃣ Why care about Gaussian Distribution?

* It helps understand probabilities—like predicting how likely a value is.

* Many real-world things (height, test scores, errors) naturally follow a Gaussian curve.

* If your data follows this distribution, you can make stronger predictions and use techniques like z-scores or confidence intervals.

### 1️⃣ Parametric Models – "Fixed Assumptions"
* These models assume a specific form for the function that maps inputs to outputs.

* They have a fixed number of parameters, no matter how much data you feed them.

* Once trained, they don't grow in complexity—they just tune their fixed parameters to fit the data.

* Example: Linear Regression

It assumes the relationship is a straight line (y = θ₀ + θ₁x) and just finds the best θ values.

### 2️⃣ Non-Parametric Models – "More Flexible, No Fixed Form"
* These models do NOT assume a fixed functional form.

* The complexity grows with the data—more data means a more complex model.

* More flexible, but can be computationally expensive.

* Example: Locally Weighted Regression

Instead of assuming a global line, it fits a local function based on nearby points.

