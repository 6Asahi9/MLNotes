* Trial and error
* Exploration vs. exploitation:
  
  Exploration: the agent tries new actions to gather more information about the environment.

  Exploitation: the agent uses the knowledge it has already gained to maximize its reward. An effective agent must explore enough to learn about the environment but also exploit its current knowledge to maximize the cumulative reward.

* Markov decision process:

  1. A set of states.

  2. A set of actions.

  3. A reward function.

  4. A transition function that determines the next state based on the current state and action
* Cumulative rewards
* Temporal difference learning
