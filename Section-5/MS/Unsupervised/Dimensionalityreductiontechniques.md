Dimensionality reduction techniques
1. Principal component analysis
2. t-Distributed stochastic neighbor embedding
3. Autoencoders
4. Linear discriminant analysis


| Technique                                                  | Type       | Supervised? | Goal                                  | Strengths ğŸŒŸ                            | Miya Reminder ğŸ¾                                 |
| ---------------------------------------------------------- | ---------- | ----------- | ------------------------------------- | --------------------------------------- | ------------------------------------------------ |
| **PCA**<br>(Principal Component Analysis)                  | Linear     | âŒ No        | Keep max variance, fewer features     | Fast, easy, good for numeric data       | â€œKeep what varies most in Miyaâ€™s dayâ€            |
| **t-SNE**<br>(t-Distributed Stochastic Neighbor Embedding) | Nonlinear  | âŒ No        | Visualize local similarity in 2D/3D   | Beautiful clusters, great for plotting  | â€œGroup Miya's favorite toys by feelingâ€          |
| **Autoencoder**                                            | Neural Net | âŒ No        | Learn how to compress & decompress    | Handles nonlinear data, learns features | â€œMiya makes her own paw-language to log her dayâ€ |
| **LDA**<br>(Linear Discriminant Analysis)                  | Linear     | âœ… Yes       | Reduce while keeping class boundaries | Perfect for classification prep         | â€œTeam Tuna vs Team Chicken stays apartâ€          |
