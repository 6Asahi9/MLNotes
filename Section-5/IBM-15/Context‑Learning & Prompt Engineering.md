Ah, now we’re diving into **AI fundamentals** — I’ll keep it clear and concise, with a little Miya flavor 😼

---

### **1️⃣ Context‑Learning (In‑Context Learning)**

* This is when an AI model **learns from examples provided *in the prompt***, without updating its internal weights.
* Basically: you give it a few examples in the same prompt, and it “figures out the pattern” to generate the next output.

**Example:**

```text
Translate English to Cat Language:
1. "I love you" -> "Purr purr"
2. "Good morning" -> "Meow meow"
3. "Time to eat" -> ?
```

AI sees the examples and outputs:

```
"Nom nom"
```

✅ No training needed — it **learns from the context you give it**.

---

### **2️⃣ Prompt Engineering**

* This is the art of **writing prompts that get the AI to do exactly what you want**.
* It’s not about changing the AI; it’s about **phrasing your request cleverly**.

**Example:**

* Weak prompt: “Tell me about cats.”
* Strong prompt: “Explain cats like I’m 5 years old, but make it funny and mention a mischievous cat named Miya.”

> Result: You get **fun, tailored answers**, not generic stuff.

---

### **Why You Should Care**

1. **Power without coding** — You can control AI behavior just by smart prompts.
2. **Customization** — Get answers in style, tone, or format you need.
3. **Efficiency** — Context + prompt engineering = AI can do complex tasks without retraining.

---

Basically: **context learning = showing examples**; **prompt engineering = asking cleverly**.
Together, they’re like teaching AI with a combination of **lesson + instruction manual**.

If you want, I can **show how to combine both to make Miya‑friendly AI prompts**, so you can get outputs in “fluffy loaf style” 😹. Want me to do that?
