# Install required libraries
!pip install nltk spacy transformers

# -----------------------------
# ğŸ“Œ NLTK (Natural Language Toolkit)
# -----------------------------
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

# Download required NLTK resources
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# Sample text
text = "Natural Language Processing is an exciting field of AI!"

# âœ… 1. Convert text to lowercase
text_lower = text.lower()

# âœ… 2. Remove punctuation
text_clean = text_lower.translate(str.maketrans("", "", string.punctuation))

# âœ… 3. Tokenization (split text into words)
tokens = word_tokenize(text_clean)
print("ğŸ”¹ Tokens:", tokens)

# âœ… 4. POS Tagging (find noun, verb, adjective, etc.)
tagged_tokens = nltk.pos_tag(tokens)
print("ğŸ”¹ POS Tags:", tagged_tokens)


# -----------------------------
# ğŸ“Œ spaCy (Modern NLP Toolkit)
# -----------------------------
import spacy

# Load pretrained small English model
nlp = spacy.load("en_core_web_sm")

# Apply NLP pipeline
doc = nlp(text)

# âœ… Named Entity Recognition (NER)
print("\nğŸ”¹ Named Entities:")
for ent in doc.ents:
    print(f"{ent.text} â†’ {ent.label_}")

# âœ… Dependency Parsing
print("\nğŸ”¹ Dependency Parsing:")
for token in doc:
    print(f"{token.text} â†’ head: {token.head.text} | dep: {token.dep_}")

# âœ… Sentence Segmentation
print("\nğŸ”¹ Sentences:")
for sent in doc.sents:
    print(sent.text)


# -----------------------------
# ğŸ“Œ Transformers (Advanced Pretrained Models)
# -----------------------------
from transformers import pipeline

# âœ… Sentiment Analysis
sentiment_analyzer = pipeline('sentiment-analysis')
sentiment_result = sentiment_analyzer(text)
print("\nğŸ”¹ Sentiment Analysis:", sentiment_result)

# âœ… Text Summarization
summarizer = pipeline('summarization')
summary = summarizer(
    text,
    max_length=50,  # max summary length
    min_length=25,  # min summary length
    do_sample=False
)
print("ğŸ”¹ Summary:", summary)


# -----------------------------
# ğŸ“ NOTES: What spaCy Gives vs. Doesn't
# -----------------------------
"""
âœ… spaCy Gives:
- Tokenization
- Lemmatization
- POS tagging
- Named Entity Recognition (NER)
- Dependency parsing
- Sentence segmentation

âŒ spaCy Does NOT Give (you need other tools):
- Sentiment analysis (use TextBlob or transformers)
- Text summarization
- Machine translation
- Pretrained chatbots or text generation

ğŸ”‘ Think:
- NLTK = basic text tools (manual)
- spaCy = modern, fast all-in-one NLP pipeline
- Transformers = advanced AI for high-level tasks
"""
