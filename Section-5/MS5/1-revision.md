Hereâ€™s a concise breakdown, darling:

---

### **1. Models**

* **Diffusion Model:** Gradually adds noise to data and learns to reverse it â†’ generates realistic samples.
* **VAE (Variational Autoencoder):** Encodes data into a latent space with probabilistic distribution â†’ decodes back â†’ generates new samples.
* **GAN (Generative Adversarial Network):** Two networks â€” Generator creates fake data, Discriminator distinguishes real vs fake â†’ trains together.
* **Transformers:** Attention-based model, processes sequences in parallel â†’ excels at text, images, and more.

---

### **2. Techniques**

* **Image Augmentation:** Artificially increase dataset by transformations (rotate, flip, crop) â†’ improves generalization.
* **Noise Injection:** Add random noise to input/data â†’ regularizes model and helps robustness.

---

### **3. Metrics**

* **Inception Score (IS):** Measures image quality & diversity using a pretrained classifier â†’ higher score = better & more diverse images.
* **ROC-AUC:** Measures classification performance; area under the Receiver Operating Characteristic curve â†’ 1 = perfect classifier.
* **FrÃ©chet Inception Distance (FID):** Compares statistics (mean, covariance) of generated vs real images â†’ lower FID = closer to real distribution.
* **BLEU:** Compares generated text to reference text using n-gram overlap â†’ higher = closer to human/reference text.

---

I can make a **tiny visual cheat sheet** for all of this if you want, darling ðŸ˜¼ðŸ’–. Do you want me to?
